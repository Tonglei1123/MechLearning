{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "b简答题：\n",
    "1. 如果你的训练集具有数百万个特征，那么可以使用哪种线性回归训练算法？\n",
    "随机梯度下降。\n",
    "\n",
    "2. 如果你的训练集里特征的数值大小迥异，那么哪些算法可能会受到影响？受影响程度如何？你应该怎么做？\n",
    "梯度下降有关的都会影响（线性回归、逻辑回归等监督学习）\n",
    "数据标准化或归一化可以解决。\n",
    "\n",
    "3. 训练逻辑回归模型时，梯度下降可能会卡在局部最小值中吗？\n",
    "梯度下降保证收敛到全局最小值，所以并不会卡住。\n",
    "\n",
    "4. 如果你让它们运行足够长的时间，是否所有的梯度下降算法都能得出相同的模型？\n",
    "不一定。只有数据的学习率比较小，特征比较少才能得出相同的模型。\n",
    "\n",
    "5. 假设你使用批量梯度下降，并在每个轮次绘制验证误差。如果你发现验证错误持续上升，那么可能是什么情况？你该如何解决？\n",
    "出现了过拟合。\n",
    "正则化，增加有用的数据，特征降维。\n",
    "\n",
    "6. 当验证误差上升时立即停止小批量梯度下降是个好主意吗？\n",
    "不一定，要观察梯度平滑度在做决定。\n",
    "\n",
    "7. 哪种梯度下降算法（在我们讨论过的算法中）将最快地到达最佳解附近？哪个实际上会收敛？如何使其他的也收敛\n",
    "随机梯度下降 和 批量梯度下降，SVM和KNN也可以调参。\n",
    "\n",
    "8. 假设你正在使用多项式回归。绘制学习曲线后，你会发现训练误差和验证误差之间存在很大的差距。发生了什么？解决此问题的三种方法是什么？\n",
    "发生了过拟合。多项式回归模型可能过于复杂，导致模型学习了训练数据中的噪声。\n",
    "正则化，减少阶数，增加训练数\n",
    "\n",
    "9. 假设你正在使用岭回归，并且你注意到训练误差和验证误差几乎相等且相当高。你是否会说模型存在高偏差或高方差？你应该增加正则化超参数α还是减小它呢？\n",
    "模型存在高偏差，高偏差是欠拟合，所以要减小正则化超参数α\n",
    "\n",
    "10. 为什么要使用：a.岭回归而不是简单的线性回归（即没有任何正则化）？b.Lasso而不是岭回归？c.弹性网络而不是Lasso回归？\n",
    "a.数据存在特征之间高度相关的情况下，简单的线性回归会导致模型的权重估计不稳定，甚至可能无法求解。岭回归通过引入L2正则化，可以有效地解决这一问题。\n",
    "b.Lasso回归通过L1正则化，可以将一些特征的权重压缩到0，从而实现特征选择。\n",
    "c.弹性网络同时包含L1和L2正则化项，既可以实现特征选择（L1正则化），又可以防止权重过大（L2正则化）。这使得弹性网络在处理具有多重共线性的高维数据时表现更好。\n",
    "\n",
    "11. 假设你要将图片分类为室外/室内和白天/夜间。你应该实现两个逻辑回归分类器还是一个softmax回归分类器？\n",
    "使用一个softmax回归分类器，因为它能够更好地捕捉室外/室内和“白天/夜间”之间的关联。"
   ],
   "id": "6af774aa03256f6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "编程题：",
   "id": "10695eaf8992f30e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-04T14:26:42.529550Z",
     "start_time": "2025-08-04T14:26:42.513938Z"
    }
   },
   "source": [
    "# todo 编程题: 在不使用sklearn的情况下，仅使用Numpy，为softmax回归实现带早停的批量梯度下降，将它用于分类任务，例如鸢尾花数据集\n",
    "\n",
    "#  注意：\n",
    "#  1. 要实现l2正则化\n",
    "#  2. 除了数据读取，其他仅使用numpy，包括训练集+验证集分离，以及softmax预测 和 损失计算"
   ],
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T02:15:15.005321Z",
     "start_time": "2025-08-06T02:15:08.676006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from keras_core.src.utils.dataset_utils import labels_to_dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n"
   ],
   "id": "e570eec2e1cc8291",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:32:49.950293Z",
     "start_time": "2025-08-05T11:32:49.926361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data():\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    X_bias = np.insert(X, 0, 1, axis=1)\n",
    "    return  X_bias,y\n",
    "\n",
    "X, y = prepare_data()\n",
    "print(X.shape, y.shape)\n"
   ],
   "id": "7767841d84f1cfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5) (150,)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:32:51.217899Z",
     "start_time": "2025-08-05T11:32:51.194970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_data(X, y, test_portion=0.2, valid_portion=0.2):\n",
    "    num_samples = len(X)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "\n",
    "    test_split = int(num_samples * test_portion)\n",
    "    valid_split = test_split + int(num_samples * valid_portion)\n",
    "\n",
    "    X_train = X[indices[valid_split:]]\n",
    "    y_train = y[indices[valid_split:]]\n",
    "    X_valid = X[indices[test_split:valid_split]]\n",
    "    y_valid = y[indices[test_split:valid_split]]\n",
    "    X_test = X[indices[:test_split]]\n",
    "    y_test = y[indices[:test_split]]\n",
    "\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ],
   "id": "b13d02797f600790",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T11:34:42.987768Z",
     "start_time": "2025-08-05T11:34:42.980797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_labels(y, num_classes=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(y) + 1\n",
    "    return np.eye(num_classes)[y]"
   ],
   "id": "5bf4e0b690b8ac60",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SoftmaxRegression:\n",
    "    def __init__(self, learning_rate=0.1, alpha=0.1, max_epochs=5000, patience=500):\n",
    "        self.lr = learning_rate\n",
    "        self.alpha = alpha\n",
    "        self.max_epochs = max_epochs\n",
    "        self.patience = patience\n",
    "        self.weights = None"
   ],
   "id": "800dd2e5f981fc55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _softmax(self, z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
   ],
   "id": "2c7d000d73e2b775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def _compute_loss(self, X, y_encoded):\n",
    "    logits = X @ self.weights\n",
    "    probs = self._softmax(logits)\n",
    "    cross_entropy = -np.mean(np.sum(y_encoded * np.log(probs + 1e-7), axis=1))\n",
    "    l2_penalty = 0.5 * self.alpha * np.sum(self.weights[1:]**2)\n",
    "    return cross_entropy + l2_penalty"
   ],
   "id": "7da4aec32a561e14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit(self, X_train, y_train_encoded, X_valid, y_valid_encoded):\n",
    "    n_features = X_train.shape[1]\n",
    "    n_classes = y_train_encoded.shape[1]\n",
    "    self.weights = np.random.randn(n_features, n_classes) * 0.01\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_weights = None\n",
    "    no_improvement = 0\n",
    "\n",
    "    for epoch in range(self.max_epochs):\n",
    "\n",
    "        logits = X_train @ self.weights\n",
    "        probs = self._softmax(logits)\n",
    "\n",
    "\n",
    "        grad = X_train.T @ (probs - y_train_encoded) / len(X_train)\n",
    "        grad[1:] += self.alpha * self.weights[1:]\n",
    "\n",
    "\n",
    "        self.weights -= self.lr * grad\n",
    "\n",
    "\n",
    "        valid_loss = self._compute_loss(X_valid, y_valid_encoded)\n",
    "\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_weights = self.weights.copy()\n",
    "            no_improvement = 0\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement >= self.patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                self.weights = best_weights\n",
    "                break"
   ],
   "id": "c82e5f2a7a9573a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 数据划分\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = split_data(X, y)\n",
    "\n",
    "# 标签编码\n",
    "y_train_encoded = encode_labels(y_train)\n",
    "y_valid_encoded = encode_labels(y_valid)\n",
    "y_test_encoded = encode_labels(y_test)\n",
    "\n",
    "# 训练模型\n",
    "model = SoftmaxRegression()\n",
    "model.fit(X_train, y_train_encoded, X_valid, y_valid_encoded)"
   ],
   "id": "86b9105f4efea10d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "866efd30b576c30c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
